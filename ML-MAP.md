---
title: 极大似然估计与最大后验估计
tags:
  - probability
  - data estimation
categories:
  - machine learning
date: 2021-03-25 19:40:04
---


## 前言

在进行分类器、回归模型等学习的时候，我们经常能看到极大似然估计(Maximum Likelihood)与最大后验估计(Maximum A Posteriori) 这两种参数估计方法。深入理解这两种方法，对后续机器学习的研究有很大的帮助。

---



## 背景

在说这两种估计方法之前，我们可以先来了解一下他们提出时的时代背景。这能让我们对他们的作用有更深刻的理解。这里我们不得不提到当时的两大概率学派：频率学派与贝叶斯学派。他们不同的世界观，直接影响了他们对概率定义的不同理解，也决定了他们估计参数的不同方法（世界观决定方法论？）。

### 频率学派

频率学派很有种决定论的哲学思想。在频率学派的学者看来，整个世界的概率应当是确定的。从本体论角度出发，可以说他们认为存在一个有着真值的“第一本体”，我们只需要去通过大量的实验去找到那个真值就好。

因此，他们所做的是对事件本身进行建模，以期通过多次重复的实验让事件概率趋向于一个稳定的值。而这个值对于每个模型而言必然是确定的，我们可以通过数学的方式来求取这个未知数。他们采用的方式就被称为**极大似然估计**。

### 贝叶斯学派

而贝叶斯学派就有种经验主义甚至康德的先验论的色彩。在他们看来，世界整体是不确定的，我们只能依赖自己的经验以及某种先验的知识对整个世界进行一个预先的估计。通过我们感官认知到的反馈，我们能够不断去调整之前的预估。这就意味着，对于不同的主观个体来说，如果一个人先前的预估不同，那么他们所认为的状态也不同。

很明显，贝叶斯学派非常依赖于这种先验的假设。他们相信模型的参数产生于某种潜在的概率分布，希望使用某种方法从数据中能够得到分布的参数。这种方法就被称为**最大后验估计**。当然，如果这种假设存在很大的误差，其结果也会不尽如人意。但如果假设比较符合实际，其效果会比频率学派更加贴合现实。

同样，我们可以看到，如果数据量非常的庞大，这种先验假设的主导作用会减弱。同时，在先验假设是均匀分布的情况下，它就等同于极大似然估计了。

### 对两种学派的总结

对于频率学派而言，万事万物是平等发生的，我们只需要通过大量的数据找到某件事物的内在概率就好。但对于贝叶斯学派而言，每件事物是否发生有着某种先验的判断。

假设我们现在要判断下雨和天上云是否浓密之间的关系，以推断今天的天气情况。对于频率学派而言，他们只需要统计一年甚至几年内的天气情况于云朵密度，并寻求模型参数。这样，单独通过今天云朵的密度，而不需要任何其他的情报，我们就能推断出今天是否下雨。

但是对于贝叶斯学派而言，他们会先统计一年甚至几年内下雨的概率（无论云朵情况如何）。他们认为，是否下雨应当符合这个潜在的概率分布，然后才考虑云朵密度和下雨之间的关系。比如在多雨地区，有云很可能代表下雨；然而在干旱地区，有云也许会推断出不会下雨。

初看之下，我们会认为贝叶斯学派更加地实际。但是，我们如何能保证我们的先验概率一定是正确的呢？我们的数据很可能并不满足我们的先验分布。因此，具体情况具体分析，不同的方法在不同的情况下会有不同的优先顺序。

之后通过公式，我们就更能直观的感受到两种方法的具体差异与联系。

---



## 极大似然估计

很多人都觉得，似然（likelihood）与概率（probability）是同一个东西。虽然他们在意义上非常相近，但在统计学具体的定义上有着非常明显的区分。简明而言，概率是已知参数预测接下来的结果，而似然是已知结果对参数进行推断。

似然函数的定义为，关于参数$\theta$的似然函数的似然函数$L(\theta|x)$ 为给定参数后变量$X$的概率：
$$
L(\theta|x)=P(X=x|\theta)
$$
 而顾名思义，极大似然估计就是找到一个$\theta$值让似然函数最大：
$$
\theta=\mathop{\arg\max}_\theta L(\theta|x)
$$
举个栗子，假设某事件结果为$A$发生的概率为$P(A)=\theta$，那么，十次事件中得到$AAAAAABBBB$的概率为:
$$
P(X=6|\theta)=L(\theta|X=6)=\theta^6(1-\theta)^4
$$

$$
\frac{dL}{d\theta}=6\times\theta^5(1-\theta)^4-4\times(1-\theta)^3\theta^6=0
$$

于是我们可以知道，当$\theta=0.6$时，似然函数取得最大值。那么我们通过极大似然估计得到的参数$\theta$即为$0.6$。

---



## 最大后验估计

极大似然估计看上去确实十分合理，但贝叶斯学派的学者却认为这结果并不合理。他会说：“我们只测试了十次，凭什么就能肯定事件结果为A的概率是60%呢？就算你测试了成百上千次，凭什么认定最后的概率一定是这个呢？我不要你觉得，我要我觉得。”

这听上去很杠精，但对于贝叶斯学派来说，脱离经验而考虑概率是不切实际的。举个例子，假设事件是从七个黄球和三个白球里随机抽一个球，结果A代表抽到的是白球。显然，根据直观经验，$P(A)=0.3$。那么，如何做到即使在十次抽取中六次是白球，我们也要让$\theta=0.3$呢？贝叶斯学派的学者设计了最大后验估计来实现。

不同于最大化似然函数，最大后验估计要求后验概率达到最大。根据贝叶斯定理，后验概率$P(\theta|X)$可以由如下公式计算:
$$
P(\theta|X)=\frac{P(X|\theta)\times P(\theta)}{P(X)}
$$

$$
\theta=\mathop{\arg\max}_\theta P(\theta|X)
$$

由于我们知道$P(X)$是一个固定值（比如十次里六次是白球，那就是0.6），因此对于[白白白白白白黄黄黄黄]的情况，我们可以知道：
$$
\theta =\mathop{arg\max}_\theta \theta^6(1-\theta^4)\times P(\theta)
$$
我们很自然的发现，比起极大似然估计，最大后验估计仅仅是多乘了一个$P(\theta)$，也就是先验概率。对于某些极端顽固分子，他们铁了心认为$\theta=0.3$（尽管这确实是事实），那么他们会将$P(\theta)$设置成：
$$
P(\theta)=
\begin{cases}
0&\theta\ne0.3\\\\
1&\theta=0.3
\end{cases}
$$
很明显，$P(\theta|X)$除了$\theta=0.3$以外，其他时候值都是0。那么毫无疑问无论实验结果如何，最后$\theta$都得是$0.3$。从这个极端的例子中，我们可以看到先验概率对参数估计的巨大影响。那么，假设这个人的先验想法是错误的，他不认为是$0.3$而认为是$0.9$，那么毫无疑问将会产生很大的谬误。

当然，情况往往不会如此极端。对于正常的贝叶斯学派学者来说，他们更倾向于使用一些数学分布来代表先验概率，例如$P(\theta)=\theta ~ N(0.3, 0.1)$，也就是平均值为0.3，方差为0.1的高斯分布。而在这种情况下，实验的数量就会起到重要作用。在较少的实验次数下，先验概率的比重很大，得到的$\theta$会向0.3靠拢。而假如实际上我们操作了10000次，前6000次都是白球（比如某人偷偷作弊把7黄3白换成了4黄6白，但是其他人不知道），那么我们的函数就会变成:
$$
\theta =\mathop{arg\max}_\theta \theta^{6000}(1-\theta^{4000})\times P(\theta)
$$
这个时候，先验概率的比重大大减小，$\theta$向0.6靠拢。

---



## 极大似然与最大后验的联系

从以上分析中，我们可以得到：

- 最大后验受主观因素影响，错误的先验概率会导向错误的结果
- 当数据量非常庞大，而先验概率并不极端时，最大后验会逐渐接近极大似然的结果
- 当先验概率为均匀分布时，最大后验等同于极大似然
- 在先验概率符合实际情况时，最大后验往往能取到更好的效果

---



## 总结与感想

有句话说的好，哲学是科学之母。对世界的不同理解，往往会导致不同的方法。这也是我喜欢哲学的原因之一。不同哲学家的学说往往能给予人启迪，使人有豁然开朗之感。

这两种方法都从概率学的角度上出发，寻求概率的最大化。虽然两者对于事件概率有着不同的理解，但本质上是一致的。然而，还有一种从损失函数出发，寻求最小损失的方法，也就是常说的最小二乘法（Least Square）。关于最小二乘法，我会留待日后探讨。

本人学艺不精，如有错漏，欢迎指出并探讨。

---



## 参考资料

统计学中的频率学派与贝叶斯学派, hgz_dm, https://blog.csdn.net/huguozhiengr/article/details/81777577

详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解, nebulaf91, https://blog.csdn.net/u011508640/article/details/72815981

极大似然估计与最大后验概率估计, 张小磊，https://zhuanlan.zhihu.com/p/40024110

频率学派还是贝叶斯学派？聊一聊机器学习中的MLE和MAP, 夏飞，https://www.sohu.com/a/215176689_610300

---

Author：Hitomichi

<span style="color: red">注：欢迎转载，请标明出处</span>

